<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MAGNeT: Multimodal Adaptive Gaussian Networks for Intent Inference in Moving Target Selection across Complex Scenarios</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
    ðŸ§² <span style="color: #e74c3c; font-weight: bold;">M</span><span style="color: #f39c12; font-weight: bold;">A</span><span style="color: #27ae60; font-weight: bold;">G</span><span style="color: #3498db; font-weight: bold;">NeT</span>: 
    <span style="color: #e74c3c; font-weight: bold;">M</span>ultimodal <span style="color: #f39c12; font-weight: bold;">A</span>daptive <span style="color: #27ae60; font-weight: bold;">G</span>aussian <span style="color: #3498db; font-weight: bold;">Net</span>works for Intent Inference in Moving Target Selection across Complex Scenarios
</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yibuxulong.github.io/" target="_blank">Xiangxian Li</a>,</span>
                <span class="author-block">
                <a href="https://scholar.google.com/citations?user=dGtfFJcAAAAJ&hl=zh-CN" target="_blank">Yawen Zheng</a><sup>*</sup>,</span>
                <span class="author-block">
                <a href="https://sleepybq.github.io/" target="_blank">Baiqiao Zhang</a>,</span>
                <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yijia Ma</a>,</span>
                <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Xianhui Cao</a>,</span>
                <span class="author-block">
                <a href="https://faculty.sdu.edu.cn/liujuan5" target="_blank">Juan Liu</a>,</span>
                <span class="author-block">
                <a href="https://yulongbian.github.io/" target="_blank">Yulong Bian</a>,</span>
                <span class="author-block">
                <a href="http://jin-huang.net/" target="_blank">Jin Huang</a>,</span>
                <span class="author-block">
                <a href="https://www.sc.sdu.edu.cn/info/1041/2193.htm" target="_blank">Chenglei Yang</a>
                <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Shandong University (SDU)</a>,</span>
                    <span class="author-block">Institute of Software Chinese Academy of Sciences (ISCAS)</a>,</span>
                    <span class="author-block">Hong Kong University of Science and Technology (HKUST)</a>, AiLF Instruments</a>,</span>
                    <span class="author-block">Shandong Key Laboratory of Intelligent Electronic Packaging Testing and Application</span>

                    <span class="author-block"><br>ACM Multimedia 2025 (Oral)</span>
                    
                  </div>

                  <div class="column has-text-centered">
                    <!-- Arxiv PDF link -->
                    <!--
                    <div class="publication-links">
                         
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    -->

                    <!-- Supplementary PDF link -->
                    
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/yibuxulong/MAGNeT" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2508.12992" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser PNG image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/carousel1.png" alt="Header Image" style="width: 100%; height: auto;">
      <h2 class="content has-text-centered">
        The motivation of our work is to adaptive single-factor uncertainty model to complex scenarios.    
      </h2>
    </div>
  </div>
</section>
<!-- End teaser PNG image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-centered">
          <p>
            Moving target selection in multimedia interactive systems faces unprecedented challenges as users increasingly interact across diverse, dynamic contextsâ€”from live streaming in moving vehicles to VR gaming in varying environments. Existing approaches rely on probabilistic models that relate endpoint distribution to target properties (size, speed). However, these methods require substantial training data for each new context and lack transferability across scenarios, limiting their practical deployment in diverse multimedia environments where rich multimodal contextual information is readily available. This paper introduces MAGNeT (Multimodal Adaptive Gaussian Networks), which addresses these problems by combining classical statistical modeling with context-aware multimodal method. MAGNeT dynamically fuses pre-fitted Ternary-Gaussian models from various scenarios based on real-time contextual cues, enabling effective adaptation with minimal training data while preserving model interpretability. We take experiments on self-constructed 2D and 3D moving target selection datasets under in-vehicle vibration conditions. Extensive experiments demonstrate that MAGNeT achieves lower error rates with few-shot samples, by applying context-aware fusion of Gaussian experts from multi-factor conditions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Illustration of the proposed MAGNeT, which features a Multimodal Context-Aware Weighting module that deciphers how prior models collaborate in a given scene. And its Gaussian Parameter Adaptive Adjustment module refines prior parameters specifically for the current context. The resulting ensemble of Gaussian distributions predicts outcomes via Gaussian mixture.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1_5.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          To collect multi-condition data (vibration, acceleration) and user interaction data, and to validate the robustness of MAGNeT under complex road conditions, a driving route was designed, as illustrated in this figure.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          In 2D scenarios, 5-shot updates reduce error rate by 0.6% - 2.5% compared with single-factor models. 
          In 3D scenarios, 2-shot user data updates reduce overall error rate by 27%.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        These visualizations present the experimental results of MAGNeT in mobile target selection tasks. Cases showing how weights are adaptively learned. For each sub-figure, we show a zoom-in scene of moving targets while user touching the screen (left), the trend of accuracy and vibration changing 3 seconds before touching (middle), the fusion weights for experts (right).
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->

<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/view.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{li2025magnet,
  title={MAGNeT: Multimodal Adaptive Gaussian Networks for Intent Inference in Moving Target Selection across Complex Scenarios},
  author={Li, Xiangxian and Zheng, Yawen and Zhang, Baiqiao and Ma, Yijia and XianhuiCao, XianhuiCao and Liu, Juan and Bian, Yulong and Huang, Jin and Yang, Chenglei},
  journal={arXiv preprint arXiv:2508.12992},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
